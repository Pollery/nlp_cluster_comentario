{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marccost\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/calculating-document-similarities-using-bert-and-other-models-b2c1a29c9630\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text \n",
    "import tensorflow as tf\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "df=pd.read_csv(f\"../data/transformed/comments_clean_sem_pequenos_e_grande.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=7kLi8u2dJz0\n",
    "# * Carregando modelos online\n",
    "\"\"\"\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\")\"\"\"\n",
    "# * Carregando modelos Local\n",
    "\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = f\"../data/model/\"\n",
    "bert_preprocess = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\"\n",
    ")\n",
    "bert_encoder = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = df[\"comment_clean\"].loc[\n",
    "    df[\"clean_comment_word_count\"] == df[\"clean_comment_word_count\"].max()\n",
    "]\n",
    "text_preprocessed = bert_preprocess(text_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_mask', 'input_type_ids', 'input_word_ids']\n",
      "Shape      : (5, 128)\n",
      "Word Ids   : [  101 31266 32965 29514 23601 10280 10173 73657 14356 13000 68868 12772]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Bert Results   : dict_keys(['default', 'encoder_outputs', 'pooled_output', 'sequence_output'])\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_encoder(text_preprocessed)\n",
    "\n",
    "print(f\"Keys       : {list(text_preprocessed.keys())}\")\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')\n",
    "print(f\"Bert Results   : {bert_results.keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepara_texto(texto):\n",
    "    texto_preprocessado = bert_preprocess(texto)\n",
    "    return bert_encoder(texto_preprocessado).get(\"pooled_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando df com os dados\n",
    "if os.path.exists(f\"../data/tmp/tmp120000.csv\") and os.path.exists(\n",
    "    f\"../data/tmp/sample120000.csv\"\n",
    "):\n",
    "    pass\n",
    "else:\n",
    "    NUM_CASES = 120000\n",
    "    MAX_CASES_LOOP = 400\n",
    "    sample_df = pd.DataFrame(\n",
    "        df.sample(NUM_CASES, random_state=1).copy().dropna()\n",
    "    )\n",
    "    comments = sample_df[\"comment_clean\"].values\n",
    "    tmp_df = pd.DataFrame()\n",
    "    # Loop carregando aos poucos\n",
    "    for i in tqdm(range(int(NUM_CASES / MAX_CASES_LOOP))):\n",
    "        tmp = prepara_texto(\n",
    "            comments[i * MAX_CASES_LOOP : (i + 1) * MAX_CASES_LOOP]\n",
    "        )\n",
    "        tmp_df = pd.concat([tmp_df, pd.DataFrame(tmp.numpy())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"../data/tmp/tmp120000.csv\") and os.path.exists(\n",
    "    f\"../data/tmp/sample120000.csv\"\n",
    "):\n",
    "    pass\n",
    "else:\n",
    "    tmp_df.to_csv(f\"../data/tmp/tmp120000.csv\", index=False)\n",
    "    sample_df.to_csv(f\"../data/tmp/sample120000.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8328dd0469c9fd14616a6cf0c2146a9f265061da664bdc72fc0cf6bd6d50ba08"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ProjetoBBUX': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
